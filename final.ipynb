{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sunwoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sunwoo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mean \n",
    "import numpy as np\n",
    "import keras \n",
    "from keras.models import Sequential, Model \n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Bidirectional, GRU, Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "#from gensim import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Reshape,SpatialDropout1D, Flatten, concatenate, Input, Conv1D, GlobalMaxPooling1D, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Bidirectional, GRU, Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_paragraph(row):\n",
    "    text = row['content']\n",
    "    text= text.lower()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = regex.sub(' ', text)\n",
    "    meaningless_words = ['words', 'business wire', 'bwr english', 'copyright', 'businesswire.com',\n",
    "                         'dow jones newswires','djdn english','dow jones institutional news', \n",
    "                         'all rights reserved', 'dow jones company inc', 'pr Newswire',\n",
    "                         'prn english', 'the wall street journal',  'dow jones & company inc',\n",
    "                         'j b4 english']\n",
    "    for words in meaningless_words:\n",
    "        text = text.replace(words, '')\n",
    "    \n",
    "    # picking paragraph containing keywords \n",
    "    text = text.split(\"/n/n\")\n",
    "    text = [para for para in text if \"license\" in para or \"licensing\" in para]\n",
    "    text = ''.join(text)\n",
    "    \n",
    "        \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    text = text.split(' ')\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    for word in text:\n",
    "        #stemmed_text.append(stemmer.stem(word))\n",
    "        stemmed_text.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    text = \" \".join(stemmed_text)\n",
    "    row['content'] = text\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_full_text(row):\n",
    "    text = row['content']\n",
    "    text= text.lower()\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    text = regex.sub(' ', text)\n",
    "    meaningless_words = ['words', 'business wire', 'bwr english', 'copyright', 'businesswire.com',\n",
    "                         'dow jones newswires','djdn english','dow jones institutional news', \n",
    "                         'all rights reserved', 'dow jones company inc', 'pr Newswire',\n",
    "                         'prn english', 'the wall street journal',  'dow jones & company inc',\n",
    "                         'j b4 english']\n",
    "    for words in meaningless_words:\n",
    "        text = text.replace(words, '')\n",
    "        \n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    text = text.split(' ')\n",
    "    text = [word for word in text if word.isalpha()]\n",
    "    \n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    for word in text:\n",
    "        #stemmed_text.append(stemmer.stem(word))\n",
    "        stemmed_text.append(lemmatizer.lemmatize(word))\n",
    "        \n",
    "    text = \" \".join(stemmed_text)\n",
    "    row['content'] = text\n",
    "    return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vm(X,y,z= None):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X) \n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = svm.SVC(kernel='linear')\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])\n",
    "        f1score = clf_report['weighted avg']['f1-score']\n",
    "        if f1score > temp:\n",
    "            new_clf = clf\n",
    "            temp = f1score\n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def random_forest(X,y,z =None):\n",
    "    clf = RandomForestClassifier()\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = RandomForestClassifier()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1score = clf_report['weighted avg']['f1-score']\n",
    "        if f1score > temp:\n",
    "            new_clf = clf\n",
    "            temp = f1score\n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def logit(X,y,z =None):\n",
    "    # Logistics Regression\n",
    "    clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "    \n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = LogisticRegression(random_state=0)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])\n",
    "        f1score = clf_report['weighted avg']['f1-score']\n",
    "        if f1score > temp:\n",
    "            new_clf = clf\n",
    "            temp = f1score\n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def xgboost(X,y,z =None):\n",
    "    clf=xgb.XGBClassifier(random_state=1,learning_rate=0.01).fit(X,y)\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = LogisticRegression(random_state=0)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])\n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def dctree(X,y,z =None):\n",
    "    clf = DecisionTreeClassifier()\n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = LogisticRegression(random_state=0)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])        \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(X,y,z =None):\n",
    "    from warnings import simplefilter\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "    lr = LogisticRegression()\n",
    "    svc = SVC(kernel='poly',probability=True)\n",
    "    dt = DecisionTreeClassifier()\n",
    "    classifiers = [('lr',lr),('dt',dt),('svc',svc)]\n",
    "    clf = VotingClassifier(estimators = classifiers, voting = 'hard')\n",
    "    \n",
    "    kf = KFold(n_splits=10)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    new_clf = LogisticRegression(random_state=0)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])        \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = new_clf.predict(z)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_net(X,y,z =None):\n",
    "    np.random.seed(1337)\n",
    "\n",
    "    nb_classes = 2\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    nb_epochs = 30\n",
    "    \n",
    "    kf = KFold(n_splits=2)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=2, random_state=123, shuffle=True)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    \n",
    "    temp = 0\n",
    "    \n",
    "    # 3 layer, Hidden layer size 1000, 500, 50 activation Relu, drop outs loss function: cross entropy batch size  = 64 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = np_utils.to_categorical(y[train_index], nb_classes), y[test_index]\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(1000,input_shape=(10000,)))\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(500))\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(50))\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(nb_classes))\n",
    "\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer= keras.optimizers.Adam(lr=5e-5, beta_1=0.9, beta_2=0.999, amsgrad=False),metrics=['acc'])\n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.15 ,epochs=nb_epochs, shuffle=True)\n",
    "        predictions = model.predict_classes(X_test,batch_size=batch_size)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])        \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = model.predict_classes(z,batch_size=batch_size)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convo_nn(X,y,z =None):\n",
    "    \n",
    "    nb_classes = 2\n",
    "    \n",
    "    kf = KFold(n_splits=2)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=2, random_state=123, shuffle=True)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    X = X.toarray()\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test =  y[train_index], y[test_index]\n",
    "        input = Input(batch_shape=(None, 10000, 1))\n",
    "        drop20 = SpatialDropout1D(0.3)(input)\n",
    "        conv2 = Conv1D(filters=128, kernel_size=3, activation='relu')(drop20)\n",
    "        drop21 = Dropout(0.5)(conv2)\n",
    "        conv22 = Conv1D(filters=64, kernel_size=3, activation='relu')(drop21)\n",
    "        drop22 = Dropout(0.5)(conv22)\n",
    "        pool2 = MaxPooling1D(pool_size=2)(drop22)\n",
    "        flat2 = Flatten()(pool2)\n",
    "        out = Dense(1, activation='sigmoid')(flat2)\n",
    "\n",
    "        model = Model(input, out)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        hist = model.fit(X_train, y_train, epochs=10, validation_split=0.15, shuffle=True, batch_size=64)\n",
    "        predictions = model.predict(X_test, batch_size=64, verbose=1)\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] > 0.5:\n",
    "                predictions[i] = 1\n",
    "            else:\n",
    "                predictions[i] = 0\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])\n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = model.predict_classes(z,batch_size=64)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTmemory(X,y,z =None):\n",
    "    max_features = 10000\n",
    "    embedding_dim = 10\n",
    "    epochs = 5\n",
    "    batch_size = 100\n",
    "    nb_classes = 2\n",
    "    \n",
    "    kf = KFold(n_splits=2)\n",
    "    kf.get_n_splits(X)\n",
    "    KFold(n_splits=2, random_state=123, shuffle=True)\n",
    "\n",
    "    accuracy=[]\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = np_utils.to_categorical(y[train_index], nb_classes), y[test_index]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(max_features, embedding_dim, input_length = X_train.shape[1]))\n",
    "        model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "        model.add(Dense(2, activation = 'softmax'))\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer= keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False),metrics = ['accuracy'])\n",
    "        print(model.summary())\n",
    "        model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_split = 0.2, callbacks = [EarlyStopping(monitor = 'val_loss', patience = 3, min_delta = 0.00001)])\n",
    "        predictions = model.predict_classes(X_test,batch_size=batch_size)\n",
    "        clf_report = classification_report(y_test, predictions, output_dict = True)\n",
    "        accuracy.append(clf_report['accuracy'])\n",
    "        precision.append(clf_report['weighted avg']['precision'])\n",
    "        recall.append(clf_report['weighted avg']['recall'])\n",
    "        f1.append(clf_report['weighted avg']['f1-score'])        \n",
    "    print(\"Accuracy: {}, Precision: {}, Recall: {}, F1-score: {}\".format(mean(accuracy),mean(precision),mean(recall),mean(f1)))\n",
    "    if z is not None:\n",
    "        predictions = model.predict_classes(z,batch_size=batch_size)\n",
    "        return predictions\n",
    "    else:\n",
    "        return None  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(training_data,type=\"binary\"):\n",
    "    \"\"\"Extract features using different methods\"\"\"\n",
    "    \n",
    "    \n",
    "    if \"binary\" in type:\n",
    "        \n",
    "        # BINARY FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=True, min_df=2, ngram_range=(1, 2), stop_words='english', max_features= 10000,strip_accents='unicode')\n",
    "        cv.fit_transform(training_data[\"content\"].values)\n",
    "\n",
    "        train_feature_set=cv.transform(training_data[\"content\"].values)\n",
    "        \n",
    "        return train_feature_set\n",
    "  \n",
    "    elif \"counts\" in type:\n",
    "        \n",
    "        # COUNT BASED FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=False, min_df=2, ngram_range=(1, 2), stop_words='english', max_features= 10000,strip_accents='unicode')\n",
    "        cv.fit_transform(training_data[\"content\"].values)\n",
    "        train_feature_set=cv.transform(training_data[\"content\"].values)\n",
    "        \n",
    "        return train_feature_set\n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # TF-IDF BASED FEATURE REPRESENTATION\n",
    "        cv=TfidfVectorizer(min_df=2, ngram_range=(1, 2), stop_words='english', max_features= 10000,strip_accents='unicode', norm='l2')\n",
    "        \n",
    "        cv.fit_transform(training_data[\"content\"].values)\n",
    "\n",
    "        train_feature_set=cv.transform(training_data[\"content\"].values)\n",
    "        \n",
    "        return train_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning_models(X,y,model,text_length,type,z=None):\n",
    "    if text_length is True:\n",
    "        X = X.apply(preprocess_paragraph, axis = 1)\n",
    "        X = extract_features(X,type=type)\n",
    "        if z is not None:\n",
    "            z = z.apply(preprocess_paragraph, axis = 1)\n",
    "            z = extract_features(z,type=type)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        X = X.apply(preprocess_full_text, axis = 1)\n",
    "        X = extract_features(X,type=type)\n",
    "        if z is not None:\n",
    "            z = z.apply(preprocess_full_text, axis = 1)\n",
    "            z = extract_features(z,type=type)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if model == 'svm':\n",
    "        z = support_vm(X,y,z)\n",
    "    elif model == 'rf':\n",
    "        z = random_forest(X,y,z)\n",
    "    elif model == 'logit':\n",
    "        z = logit(X,y,z)\n",
    "    elif model == 'xgb':\n",
    "        z = xgboost(X,y,z)\n",
    "    elif model == 'cnn':\n",
    "        z = convo_nn(X,y,z)\n",
    "    elif model == 'lstm':\n",
    "        z = LSTmemory(X,y,z)\n",
    "    elif model == 'dct':\n",
    "        z = dctree(X,y,z)\n",
    "    elif model == 'voting':\n",
    "        z = voting(X,y,z)\n",
    "    else:\n",
    "        z = feedforward_net(X,y,z)\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MASTER_TRAINING.xlsx'\n",
    "X = pd.read_excel(path)\n",
    "columns = ['content', 'licensing_agreement']\n",
    "X = X[columns]\n",
    "X = X.dropna(subset = ['licensing_agreement'])\n",
    "y = X['licensing_agreement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.read_csv('2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78500500607881, Precision: 0.8106178057694198, Recall: 0.78500500607881, F1-score: 0.777103829942487\n",
      "Accuracy: 0.7714742902095402, Precision: 0.7969097425243691, Recall: 0.7714742902095402, F1-score: 0.7625165822356037\n",
      "Accuracy: 0.7854340985482371, Precision: 0.8125116939386764, Recall: 0.7854340985482371, F1-score: 0.7773849006361659\n",
      "Accuracy: 0.7964152899949939, Precision: 0.8168085676317636, Recall: 0.7964152899949939, F1-score: 0.7906343724110119\n",
      "Accuracy: 0.7955731960237431, Precision: 0.8148391180884533, Recall: 0.7955731960237431, F1-score: 0.7898419651662243\n",
      "Accuracy: 0.7799184724308088, Precision: 0.8024805117071274, Recall: 0.7799184724308088, F1-score: 0.7724652164887211\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'voting', True, type='tfidf')\n",
    "machine_learning_models(X,y,'voting', True, type='binary')\n",
    "machine_learning_models(X,y,'voting', True, type='count')\n",
    "machine_learning_models(X,y,'voting', False, type='tfidf')\n",
    "machine_learning_models(X,y,'voting', False, type='count')\n",
    "machine_learning_models(X,y,'voting', False, type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.790908603304012, Precision: 0.7992307625065564, Recall: 0.790908603304012, F1-score: 0.7891153323216827\n",
      "Accuracy: 0.7570746620896803, Precision: 0.7708721344808916, Recall: 0.7570746620896803, F1-score: 0.7539331748316717\n",
      "Accuracy: 0.813748837874562, Precision: 0.8214044370075727, Recall: 0.813748837874562, F1-score: 0.8118173579842061\n",
      "Accuracy: 0.7718801401702067, Precision: 0.7782662332729737, Recall: 0.7718801401702067, F1-score: 0.7710506282995995\n",
      "Accuracy: 0.7769648859329186, Precision: 0.782532198645103, Recall: 0.7769648859329186, F1-score: 0.7763827055514145\n",
      "Accuracy: 0.8116570120861045, Precision: 0.8142204905378789, Recall: 0.8116570120861045, F1-score: 0.8115667961740902\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'svm',True,type=\"binary\")\n",
    "machine_learning_models(X,y,'svm',True,type=\"counts\")\n",
    "machine_learning_models(X,y,'svm',True,type=\"tfidf\")\n",
    "machine_learning_models(X,y,'svm',False,type=\"binary\")\n",
    "machine_learning_models(X,y,'svm',False,type=\"counts\")\n",
    "machine_learning_models(X,y,'svm',False,type=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7799399270542802, Precision: 0.7887309000202752, Recall: 0.7799399270542802, F1-score: 0.7765061452592132\n",
      "Accuracy: 0.7854591289422871, Precision: 0.7956111185610738, Recall: 0.7854591289422871, F1-score: 0.7823906529311617\n",
      "Accuracy: 0.7651702066795395, Precision: 0.7764758605150585, Recall: 0.7651702066795395, F1-score: 0.7616400505679016\n",
      "Accuracy: 0.7854305227776586, Precision: 0.7949019195896372, Recall: 0.7854305227776586, F1-score: 0.782900736340923\n",
      "Accuracy: 0.7850032181935207, Precision: 0.7964923812672423, Recall: 0.7850032181935207, F1-score: 0.7819347354499013\n",
      "Accuracy: 0.7689801902309947, Precision: 0.7816960411083437, Recall: 0.7689801902309947, F1-score: 0.7646248873300331\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'rf',True,type=\"binary\")\n",
    "machine_learning_models(X,y,'rf',True,type=\"counts\")\n",
    "machine_learning_models(X,y,'rf',True,type=\"tfidf\")\n",
    "machine_learning_models(X,y,'rf',False,type=\"binary\")\n",
    "machine_learning_models(X,y,'rf',False,type=\"counts\")\n",
    "machine_learning_models(X,y,'rf',False,type=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8183884002002432, Precision: 0.8260482828611077, Recall: 0.8183884002002432, F1-score: 0.816466729243373\n",
      "Accuracy: 0.8128817135092612, Precision: 0.8213530393768742, Recall: 0.8128817135092612, F1-score: 0.8109287561381117\n",
      "Accuracy: 0.823887935350068, Precision: 0.8328068869525717, Recall: 0.823887935350068, F1-score: 0.8219948067838223\n",
      "Accuracy: 0.8170975470213832, Precision: 0.8216041955498405, Recall: 0.8170975470213832, F1-score: 0.8161467315603862\n",
      "Accuracy: 0.8065400843881857, Precision: 0.8116872686650721, Recall: 0.8065400843881857, F1-score: 0.805821163701258\n",
      "Accuracy: 0.8302224129299864, Precision: 0.8337294455875043, Recall: 0.8302224129299864, F1-score: 0.8296743581190806\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'logit',True,type=\"binary\")\n",
    "machine_learning_models(X,y,'logit',True,type=\"counts\")\n",
    "machine_learning_models(X,y,'logit',True,type=\"tfidf\")\n",
    "machine_learning_models(X,y,'logit',False,type=\"binary\")\n",
    "machine_learning_models(X,y,'logit',False,type=\"counts\")\n",
    "machine_learning_models(X,y,'logit',False,type=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7731656296931989, Precision: 0.7853375211237872, Recall: 0.7731656296931989, F1-score: 0.7703773425555043\n",
      "Accuracy: 0.7799506543660158, Precision: 0.7910959578407073, Recall: 0.7799506543660158, F1-score: 0.7768099659240104\n",
      "Accuracy: 0.787534863763141, Precision: 0.7971109256330073, Recall: 0.787534863763141, F1-score: 0.7842189264790582\n",
      "Accuracy: 0.7773814632053208, Precision: 0.7881355875454753, Recall: 0.7773814632053208, F1-score: 0.7755774837920097\n",
      "Accuracy: 0.7812093256096688, Precision: 0.7910415349552208, Recall: 0.7812093256096688, F1-score: 0.7791019420040333\n",
      "Accuracy: 0.7866802545948652, Precision: 0.7948739036116249, Recall: 0.7866802545948652, F1-score: 0.784344186595227\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'xgb',True,type=\"binary\")\n",
    "machine_learning_models(X,y,'xgb',True,type=\"counts\")\n",
    "machine_learning_models(X,y,'xgb',True,type=\"tfidf\")\n",
    "machine_learning_models(X,y,'xgb',False,type=\"binary\")\n",
    "machine_learning_models(X,y,'xgb',False,type=\"counts\")\n",
    "machine_learning_models(X,y,'xgb',False,type=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 11s 11ms/step - loss: 0.6935 - acc: 0.4995 - val_loss: 0.6913 - val_acc: 0.5730\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.6900 - acc: 0.5751 - val_loss: 0.6871 - val_acc: 0.6292\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6856 - acc: 0.6209 - val_loss: 0.6818 - val_acc: 0.6292\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6811 - acc: 0.6428 - val_loss: 0.6745 - val_acc: 0.6292\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6725 - acc: 0.6697 - val_loss: 0.6646 - val_acc: 0.6348\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6640 - acc: 0.6896 - val_loss: 0.6510 - val_acc: 0.6517\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6476 - acc: 0.7234 - val_loss: 0.6318 - val_acc: 0.6798\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6300 - acc: 0.7562 - val_loss: 0.6071 - val_acc: 0.7191\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6021 - acc: 0.8090 - val_loss: 0.5764 - val_acc: 0.7584\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5708 - acc: 0.8299 - val_loss: 0.5396 - val_acc: 0.7865\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5239 - acc: 0.8597 - val_loss: 0.4995 - val_acc: 0.8371\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4831 - acc: 0.8746 - val_loss: 0.4583 - val_acc: 0.8933\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4320 - acc: 0.9055 - val_loss: 0.4194 - val_acc: 0.9101\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 6s 5ms/step - loss: 0.3929 - acc: 0.9104 - val_loss: 0.3872 - val_acc: 0.9157\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3474 - acc: 0.9224 - val_loss: 0.3605 - val_acc: 0.9101\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3066 - acc: 0.9274 - val_loss: 0.3395 - val_acc: 0.9101\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.2732 - acc: 0.9333 - val_loss: 0.3227 - val_acc: 0.9101\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.2352 - acc: 0.9443 - val_loss: 0.3114 - val_acc: 0.9157\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1955 - acc: 0.9662 - val_loss: 0.3023 - val_acc: 0.9157\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1803 - acc: 0.9662 - val_loss: 0.2936 - val_acc: 0.9213\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.1606 - acc: 0.9701 - val_loss: 0.2917 - val_acc: 0.9213\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.1376 - acc: 0.9751 - val_loss: 0.2878 - val_acc: 0.9213\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1205 - acc: 0.9831 - val_loss: 0.2861 - val_acc: 0.9213\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1048 - acc: 0.9881 - val_loss: 0.2863 - val_acc: 0.9213\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0939 - acc: 0.9881 - val_loss: 0.2859 - val_acc: 0.9213\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0865 - acc: 0.9881 - val_loss: 0.2869 - val_acc: 0.9213\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0765 - acc: 0.9891 - val_loss: 0.2903 - val_acc: 0.9213\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0590 - acc: 0.9920 - val_loss: 0.2924 - val_acc: 0.9213\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0593 - acc: 0.9930 - val_loss: 0.2998 - val_acc: 0.8989\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0488 - acc: 0.9950 - val_loss: 0.3011 - val_acc: 0.9045\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.6925 - acc: 0.5119 - val_loss: 0.6933 - val_acc: 0.4663\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 6s 5ms/step - loss: 0.6901 - acc: 0.5895 - val_loss: 0.6920 - val_acc: 0.5281\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6886 - acc: 0.5964 - val_loss: 0.6906 - val_acc: 0.5449\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 6s 5ms/step - loss: 0.6852 - acc: 0.6342 - val_loss: 0.6886 - val_acc: 0.6180\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6813 - acc: 0.6640 - val_loss: 0.6857 - val_acc: 0.6348\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6758 - acc: 0.7018 - val_loss: 0.6819 - val_acc: 0.6404\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6684 - acc: 0.7237 - val_loss: 0.6759 - val_acc: 0.6854\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6582 - acc: 0.7614 - val_loss: 0.6688 - val_acc: 0.6910\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6430 - acc: 0.8052 - val_loss: 0.6596 - val_acc: 0.6966\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6269 - acc: 0.8042 - val_loss: 0.6465 - val_acc: 0.7135\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6014 - acc: 0.8280 - val_loss: 0.6303 - val_acc: 0.7247\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5717 - acc: 0.8449 - val_loss: 0.6123 - val_acc: 0.7303\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5383 - acc: 0.8668 - val_loss: 0.5926 - val_acc: 0.7416\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5006 - acc: 0.8748 - val_loss: 0.5699 - val_acc: 0.7472\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4560 - acc: 0.8877 - val_loss: 0.5523 - val_acc: 0.7472\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4120 - acc: 0.8936 - val_loss: 0.5333 - val_acc: 0.7416\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 6s 5ms/step - loss: 0.3808 - acc: 0.9046 - val_loss: 0.5191 - val_acc: 0.7360\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3361 - acc: 0.9105 - val_loss: 0.5197 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3073 - acc: 0.9235 - val_loss: 0.5037 - val_acc: 0.7416\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.2673 - acc: 0.9304 - val_loss: 0.4976 - val_acc: 0.7472\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2475 - acc: 0.9374 - val_loss: 0.5009 - val_acc: 0.7528\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2307 - acc: 0.9334 - val_loss: 0.5001 - val_acc: 0.7584\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2103 - acc: 0.9394 - val_loss: 0.5117 - val_acc: 0.7528\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1959 - acc: 0.9364 - val_loss: 0.5268 - val_acc: 0.7416\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1783 - acc: 0.9463 - val_loss: 0.5238 - val_acc: 0.7584\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1762 - acc: 0.9414 - val_loss: 0.5373 - val_acc: 0.7472\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 6s 5ms/step - loss: 0.1735 - acc: 0.9384 - val_loss: 0.5415 - val_acc: 0.7584\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1596 - acc: 0.9423 - val_loss: 0.5485 - val_acc: 0.7584\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.1489 - acc: 0.9483 - val_loss: 0.5632 - val_acc: 0.7528\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.1461 - acc: 0.9453 - val_loss: 0.5572 - val_acc: 0.7640\n",
      "Accuracy: 0.8145418770418771, Precision: 0.8156729378809877, Recall: 0.8145418770418771, F1-score: 0.8138403763567681\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',True,type=\"tfidf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.7312 - acc: 0.4935 - val_loss: 0.6367 - val_acc: 0.6966\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6682 - acc: 0.6030 - val_loss: 0.6026 - val_acc: 0.6854\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6406 - acc: 0.6259 - val_loss: 0.5645 - val_acc: 0.7472\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5927 - acc: 0.6975 - val_loss: 0.5184 - val_acc: 0.8427\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5566 - acc: 0.7353 - val_loss: 0.4724 - val_acc: 0.8652\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5342 - acc: 0.7502 - val_loss: 0.4308 - val_acc: 0.8764\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4956 - acc: 0.7791 - val_loss: 0.3983 - val_acc: 0.8820\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4636 - acc: 0.8100 - val_loss: 0.3676 - val_acc: 0.9045\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4146 - acc: 0.8378 - val_loss: 0.3433 - val_acc: 0.9045\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3846 - acc: 0.8428 - val_loss: 0.3221 - val_acc: 0.9101\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3536 - acc: 0.8577 - val_loss: 0.3086 - val_acc: 0.9213\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3218 - acc: 0.8925 - val_loss: 0.2971 - val_acc: 0.9157\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.2820 - acc: 0.9045 - val_loss: 0.2919 - val_acc: 0.9213\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2629 - acc: 0.9035 - val_loss: 0.2875 - val_acc: 0.9213\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2266 - acc: 0.9303 - val_loss: 0.2886 - val_acc: 0.9157\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1984 - acc: 0.9453 - val_loss: 0.2914 - val_acc: 0.9101\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1813 - acc: 0.9532 - val_loss: 0.2928 - val_acc: 0.9045\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.1621 - acc: 0.9632 - val_loss: 0.2972 - val_acc: 0.9101\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1552 - acc: 0.9552 - val_loss: 0.2975 - val_acc: 0.9157\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.1321 - acc: 0.9682 - val_loss: 0.3026 - val_acc: 0.9101\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1210 - acc: 0.9672 - val_loss: 0.3192 - val_acc: 0.8989\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.1025 - acc: 0.9771 - val_loss: 0.3150 - val_acc: 0.9157\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0962 - acc: 0.9771 - val_loss: 0.3212 - val_acc: 0.9101\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0935 - acc: 0.9821 - val_loss: 0.3340 - val_acc: 0.9045\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0797 - acc: 0.9831 - val_loss: 0.3450 - val_acc: 0.9045\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0749 - acc: 0.9841 - val_loss: 0.3470 - val_acc: 0.9045\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0657 - acc: 0.9920 - val_loss: 0.3609 - val_acc: 0.8989\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0566 - acc: 0.9960 - val_loss: 0.3695 - val_acc: 0.8989\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0563 - acc: 0.9920 - val_loss: 0.3704 - val_acc: 0.9045\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0556 - acc: 0.9851 - val_loss: 0.3920 - val_acc: 0.8989\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 8s 8ms/step - loss: 0.6994 - acc: 0.4901 - val_loss: 0.6785 - val_acc: 0.5955\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.6840 - acc: 0.5258 - val_loss: 0.6708 - val_acc: 0.6180\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6559 - acc: 0.6113 - val_loss: 0.6582 - val_acc: 0.6798\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.6402 - acc: 0.6511 - val_loss: 0.6390 - val_acc: 0.7584\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6223 - acc: 0.6809 - val_loss: 0.6180 - val_acc: 0.7584\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.5946 - acc: 0.7167 - val_loss: 0.5938 - val_acc: 0.7472\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5611 - acc: 0.7594 - val_loss: 0.5644 - val_acc: 0.7528\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.5413 - acc: 0.7684 - val_loss: 0.5389 - val_acc: 0.7697\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5141 - acc: 0.7704 - val_loss: 0.5227 - val_acc: 0.7753\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4756 - acc: 0.8231 - val_loss: 0.5172 - val_acc: 0.7640\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4443 - acc: 0.8559 - val_loss: 0.5122 - val_acc: 0.7697\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4184 - acc: 0.8499 - val_loss: 0.5125 - val_acc: 0.7697\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.3900 - acc: 0.8728 - val_loss: 0.5242 - val_acc: 0.7697\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.3710 - acc: 0.8738 - val_loss: 0.5293 - val_acc: 0.7697\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3437 - acc: 0.8827 - val_loss: 0.5319 - val_acc: 0.7865\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.3311 - acc: 0.8897 - val_loss: 0.5441 - val_acc: 0.7640\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.3177 - acc: 0.8926 - val_loss: 0.5686 - val_acc: 0.7640\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.2922 - acc: 0.9076 - val_loss: 0.6002 - val_acc: 0.7640\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.2796 - acc: 0.9175 - val_loss: 0.6320 - val_acc: 0.7640\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2706 - acc: 0.9105 - val_loss: 0.6375 - val_acc: 0.7809\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2471 - acc: 0.9185 - val_loss: 0.6537 - val_acc: 0.7753\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2424 - acc: 0.9215 - val_loss: 0.6750 - val_acc: 0.7809\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2362 - acc: 0.9254 - val_loss: 0.7018 - val_acc: 0.7753\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2231 - acc: 0.9294 - val_loss: 0.7120 - val_acc: 0.7921\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2186 - acc: 0.9304 - val_loss: 0.7287 - val_acc: 0.7978\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1992 - acc: 0.9314 - val_loss: 0.7473 - val_acc: 0.7921\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2052 - acc: 0.9314 - val_loss: 0.7764 - val_acc: 0.7865\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1965 - acc: 0.9354 - val_loss: 0.8147 - val_acc: 0.7865\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.1887 - acc: 0.9334 - val_loss: 0.8469 - val_acc: 0.7865\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.1813 - acc: 0.9354 - val_loss: 0.8660 - val_acc: 0.7865\n",
      "Accuracy: 0.8255241055721825, Precision: 0.827076328504134, Recall: 0.8255241055721825, F1-score: 0.8250466241826975\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',True,type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 7s 7ms/step - loss: 1.2108 - acc: 0.4915 - val_loss: 0.6360 - val_acc: 0.5506\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.9232 - acc: 0.5363 - val_loss: 0.6058 - val_acc: 0.5618\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.8030 - acc: 0.5572 - val_loss: 0.5522 - val_acc: 0.6236\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.7097 - acc: 0.6299 - val_loss: 0.5186 - val_acc: 0.6573\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.7132 - acc: 0.6348 - val_loss: 0.4958 - val_acc: 0.6854\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6191 - acc: 0.6796 - val_loss: 0.4818 - val_acc: 0.7022\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.5912 - acc: 0.7184 - val_loss: 0.4685 - val_acc: 0.7584\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6027 - acc: 0.6985 - val_loss: 0.4518 - val_acc: 0.7978\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5502 - acc: 0.7234 - val_loss: 0.4382 - val_acc: 0.7921\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.5260 - acc: 0.7502 - val_loss: 0.4243 - val_acc: 0.7978\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5059 - acc: 0.7900 - val_loss: 0.4123 - val_acc: 0.8034\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4752 - acc: 0.8020 - val_loss: 0.3987 - val_acc: 0.8371\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4440 - acc: 0.8209 - val_loss: 0.3843 - val_acc: 0.8708\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4279 - acc: 0.8179 - val_loss: 0.3726 - val_acc: 0.8652\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4352 - acc: 0.8080 - val_loss: 0.3590 - val_acc: 0.8708\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3878 - acc: 0.8408 - val_loss: 0.3493 - val_acc: 0.8820\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3766 - acc: 0.8697 - val_loss: 0.3397 - val_acc: 0.8652\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.3693 - acc: 0.8766 - val_loss: 0.3327 - val_acc: 0.8820\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 7s 7ms/step - loss: 0.3186 - acc: 0.8866 - val_loss: 0.3267 - val_acc: 0.8876\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.3128 - acc: 0.8915 - val_loss: 0.3213 - val_acc: 0.8933\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3148 - acc: 0.8806 - val_loss: 0.3154 - val_acc: 0.8764\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2859 - acc: 0.8995 - val_loss: 0.3140 - val_acc: 0.8820\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2712 - acc: 0.9025 - val_loss: 0.3116 - val_acc: 0.8820\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2407 - acc: 0.9184 - val_loss: 0.3091 - val_acc: 0.8708\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2236 - acc: 0.9264 - val_loss: 0.3080 - val_acc: 0.8764\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.2409 - acc: 0.9154 - val_loss: 0.3094 - val_acc: 0.8820\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2128 - acc: 0.9313 - val_loss: 0.3128 - val_acc: 0.8933\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2049 - acc: 0.9254 - val_loss: 0.3129 - val_acc: 0.8876\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1994 - acc: 0.9413 - val_loss: 0.3155 - val_acc: 0.8820\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1858 - acc: 0.9502 - val_loss: 0.3185 - val_acc: 0.8820\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.8534 - acc: 0.5398 - val_loss: 0.6835 - val_acc: 0.5393\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.7754 - acc: 0.5905 - val_loss: 0.6736 - val_acc: 0.6124\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.7154 - acc: 0.6083 - val_loss: 0.6565 - val_acc: 0.6348\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6769 - acc: 0.5944 - val_loss: 0.6441 - val_acc: 0.6629\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 5s 4ms/step - loss: 0.6529 - acc: 0.6501 - val_loss: 0.6333 - val_acc: 0.7022\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6084 - acc: 0.6640 - val_loss: 0.6243 - val_acc: 0.7022\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6045 - acc: 0.6879 - val_loss: 0.6168 - val_acc: 0.7022\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5824 - acc: 0.6968 - val_loss: 0.6078 - val_acc: 0.7360\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5832 - acc: 0.6918 - val_loss: 0.6005 - val_acc: 0.7360\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5340 - acc: 0.7286 - val_loss: 0.5895 - val_acc: 0.7472\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5722 - acc: 0.7425 - val_loss: 0.5827 - val_acc: 0.7416\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5425 - acc: 0.7634 - val_loss: 0.5772 - val_acc: 0.7416\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5010 - acc: 0.7734 - val_loss: 0.5728 - val_acc: 0.7416\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4752 - acc: 0.7962 - val_loss: 0.5736 - val_acc: 0.7303\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4764 - acc: 0.7893 - val_loss: 0.5776 - val_acc: 0.7247\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4464 - acc: 0.8111 - val_loss: 0.5770 - val_acc: 0.7416\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4565 - acc: 0.8211 - val_loss: 0.5830 - val_acc: 0.7472\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4389 - acc: 0.8370 - val_loss: 0.5873 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.4080 - acc: 0.8300 - val_loss: 0.5953 - val_acc: 0.7528\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.4066 - acc: 0.8390 - val_loss: 0.5919 - val_acc: 0.7528\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 6s 5ms/step - loss: 0.3863 - acc: 0.8618 - val_loss: 0.5932 - val_acc: 0.7528\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.3892 - acc: 0.8579 - val_loss: 0.5925 - val_acc: 0.7584\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3620 - acc: 0.8588 - val_loss: 0.6004 - val_acc: 0.7584\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3496 - acc: 0.8887 - val_loss: 0.6046 - val_acc: 0.7697\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3554 - acc: 0.8678 - val_loss: 0.6247 - val_acc: 0.7640\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3306 - acc: 0.8827 - val_loss: 0.6405 - val_acc: 0.7753\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.3242 - acc: 0.8936 - val_loss: 0.6393 - val_acc: 0.7697\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3187 - acc: 0.8907 - val_loss: 0.6500 - val_acc: 0.7697\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3181 - acc: 0.8946 - val_loss: 0.6726 - val_acc: 0.7921\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.2951 - acc: 0.8986 - val_loss: 0.6811 - val_acc: 0.7865\n",
      "Accuracy: 0.8179227542208312, Precision: 0.821981091956962, Recall: 0.8179227542208312, F1-score: 0.8163925455739205\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',True,type='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 1.0961 - acc: 0.5065 - val_loss: 0.5711 - val_acc: 0.6011\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.8883 - acc: 0.5473 - val_loss: 0.5425 - val_acc: 0.6180\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.7718 - acc: 0.5920 - val_loss: 0.4997 - val_acc: 0.6573\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.7005 - acc: 0.6318 - val_loss: 0.4740 - val_acc: 0.7191\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6485 - acc: 0.6706 - val_loss: 0.4613 - val_acc: 0.7584\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6410 - acc: 0.6816 - val_loss: 0.4514 - val_acc: 0.7640\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5696 - acc: 0.7045 - val_loss: 0.4400 - val_acc: 0.7753\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5366 - acc: 0.7343 - val_loss: 0.4263 - val_acc: 0.8034\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5466 - acc: 0.7343 - val_loss: 0.4111 - val_acc: 0.8427\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5268 - acc: 0.7483 - val_loss: 0.3994 - val_acc: 0.8427\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4999 - acc: 0.7781 - val_loss: 0.3855 - val_acc: 0.8427\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4829 - acc: 0.7841 - val_loss: 0.3711 - val_acc: 0.8596\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4592 - acc: 0.8040 - val_loss: 0.3620 - val_acc: 0.8652\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4087 - acc: 0.8179 - val_loss: 0.3519 - val_acc: 0.8708\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.4143 - acc: 0.8159 - val_loss: 0.3420 - val_acc: 0.8876\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4032 - acc: 0.8418 - val_loss: 0.3343 - val_acc: 0.8876\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3871 - acc: 0.8527 - val_loss: 0.3284 - val_acc: 0.8933\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.3352 - acc: 0.8697 - val_loss: 0.3216 - val_acc: 0.8933\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3255 - acc: 0.8846 - val_loss: 0.3123 - val_acc: 0.8933\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3317 - acc: 0.8786 - val_loss: 0.3052 - val_acc: 0.9045\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3116 - acc: 0.8836 - val_loss: 0.3001 - val_acc: 0.9101\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.2723 - acc: 0.9035 - val_loss: 0.2953 - val_acc: 0.9101\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2550 - acc: 0.9154 - val_loss: 0.2930 - val_acc: 0.9101\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2461 - acc: 0.9154 - val_loss: 0.2948 - val_acc: 0.9101\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.2229 - acc: 0.9294 - val_loss: 0.2975 - val_acc: 0.9157\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2333 - acc: 0.9164 - val_loss: 0.3000 - val_acc: 0.9101\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2100 - acc: 0.9254 - val_loss: 0.3028 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1865 - acc: 0.9393 - val_loss: 0.3047 - val_acc: 0.9157\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.1735 - acc: 0.9393 - val_loss: 0.3069 - val_acc: 0.9101\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1713 - acc: 0.9393 - val_loss: 0.3118 - val_acc: 0.9101\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.7866 - acc: 0.5368 - val_loss: 0.6629 - val_acc: 0.6011\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.7630 - acc: 0.5537 - val_loss: 0.6412 - val_acc: 0.6742\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.7046 - acc: 0.5944 - val_loss: 0.6259 - val_acc: 0.7079\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6707 - acc: 0.6193 - val_loss: 0.6136 - val_acc: 0.7303\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6235 - acc: 0.6441 - val_loss: 0.6042 - val_acc: 0.7472\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6057 - acc: 0.6571 - val_loss: 0.5944 - val_acc: 0.7528\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6176 - acc: 0.6660 - val_loss: 0.5844 - val_acc: 0.7472\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.5754 - acc: 0.6978 - val_loss: 0.5769 - val_acc: 0.7528\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5722 - acc: 0.7346 - val_loss: 0.5670 - val_acc: 0.7472\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5419 - acc: 0.7425 - val_loss: 0.5610 - val_acc: 0.7584\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5294 - acc: 0.7594 - val_loss: 0.5541 - val_acc: 0.7584\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4887 - acc: 0.7903 - val_loss: 0.5480 - val_acc: 0.7584\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4969 - acc: 0.7714 - val_loss: 0.5417 - val_acc: 0.7640\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5008 - acc: 0.7763 - val_loss: 0.5376 - val_acc: 0.7640\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.4599 - acc: 0.8320 - val_loss: 0.5397 - val_acc: 0.7528\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4445 - acc: 0.8181 - val_loss: 0.5384 - val_acc: 0.7640\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4122 - acc: 0.8340 - val_loss: 0.5464 - val_acc: 0.7640\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 5s 4ms/step - loss: 0.4113 - acc: 0.8459 - val_loss: 0.5567 - val_acc: 0.7528\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3943 - acc: 0.8479 - val_loss: 0.5590 - val_acc: 0.7472\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3715 - acc: 0.8907 - val_loss: 0.5509 - val_acc: 0.7472\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3500 - acc: 0.9036 - val_loss: 0.5609 - val_acc: 0.7472\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 5s 4ms/step - loss: 0.3460 - acc: 0.8847 - val_loss: 0.5743 - val_acc: 0.7472\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3409 - acc: 0.8926 - val_loss: 0.5909 - val_acc: 0.7472\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3334 - acc: 0.8757 - val_loss: 0.5909 - val_acc: 0.7472\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.3118 - acc: 0.9135 - val_loss: 0.5965 - val_acc: 0.7528\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3032 - acc: 0.9125 - val_loss: 0.6204 - val_acc: 0.7472\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2928 - acc: 0.9225 - val_loss: 0.6368 - val_acc: 0.7472\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3008 - acc: 0.9115 - val_loss: 0.6504 - val_acc: 0.7416\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2853 - acc: 0.9334 - val_loss: 0.6634 - val_acc: 0.7416\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2654 - acc: 0.9374 - val_loss: 0.6898 - val_acc: 0.7416\n",
      "Accuracy: 0.8191864333691257, Precision: 0.8202205040652848, Recall: 0.8191864333691257, F1-score: 0.8188621410821841\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',False,type='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.7447 - acc: 0.4995 - val_loss: 0.6388 - val_acc: 0.6461\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6831 - acc: 0.5950 - val_loss: 0.5889 - val_acc: 0.6910\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6262 - acc: 0.6328 - val_loss: 0.5474 - val_acc: 0.7472\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5951 - acc: 0.6667 - val_loss: 0.5085 - val_acc: 0.8034\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5613 - acc: 0.7134 - val_loss: 0.4734 - val_acc: 0.8371\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.5329 - acc: 0.7522 - val_loss: 0.4414 - val_acc: 0.8427\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4874 - acc: 0.7881 - val_loss: 0.4117 - val_acc: 0.8539\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.4647 - acc: 0.8010 - val_loss: 0.3831 - val_acc: 0.8764\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4164 - acc: 0.8398 - val_loss: 0.3601 - val_acc: 0.8708\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3963 - acc: 0.8448 - val_loss: 0.3457 - val_acc: 0.8764\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.3625 - acc: 0.8697 - val_loss: 0.3320 - val_acc: 0.8764\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3193 - acc: 0.8856 - val_loss: 0.3237 - val_acc: 0.8708\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2817 - acc: 0.9065 - val_loss: 0.3150 - val_acc: 0.8820\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2684 - acc: 0.9015 - val_loss: 0.3095 - val_acc: 0.8820\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2311 - acc: 0.9284 - val_loss: 0.3098 - val_acc: 0.8652\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2159 - acc: 0.9224 - val_loss: 0.3098 - val_acc: 0.8652\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.1965 - acc: 0.9393 - val_loss: 0.3125 - val_acc: 0.8764\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1769 - acc: 0.9502 - val_loss: 0.3234 - val_acc: 0.8708\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1479 - acc: 0.9592 - val_loss: 0.3302 - val_acc: 0.8652\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1392 - acc: 0.9622 - val_loss: 0.3304 - val_acc: 0.8708\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1163 - acc: 0.9721 - val_loss: 0.3338 - val_acc: 0.8876\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1066 - acc: 0.9811 - val_loss: 0.3494 - val_acc: 0.8708\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0907 - acc: 0.9771 - val_loss: 0.3465 - val_acc: 0.8820\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 4ms/step - loss: 0.0887 - acc: 0.9791 - val_loss: 0.3541 - val_acc: 0.8820\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0735 - acc: 0.9871 - val_loss: 0.3615 - val_acc: 0.8876\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0658 - acc: 0.9881 - val_loss: 0.3666 - val_acc: 0.8876\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0695 - acc: 0.9821 - val_loss: 0.3833 - val_acc: 0.8820\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0649 - acc: 0.9861 - val_loss: 0.3839 - val_acc: 0.8876\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0503 - acc: 0.9940 - val_loss: 0.3961 - val_acc: 0.8876\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.0482 - acc: 0.9920 - val_loss: 0.4077 - val_acc: 0.8876\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.7124 - acc: 0.5338 - val_loss: 0.6842 - val_acc: 0.5449\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6858 - acc: 0.5726 - val_loss: 0.6662 - val_acc: 0.6517\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6468 - acc: 0.6133 - val_loss: 0.6508 - val_acc: 0.6966\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6468 - acc: 0.6292 - val_loss: 0.6358 - val_acc: 0.7303\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6046 - acc: 0.6879 - val_loss: 0.6185 - val_acc: 0.7247\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.5799 - acc: 0.6779 - val_loss: 0.5941 - val_acc: 0.7528\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5506 - acc: 0.7425 - val_loss: 0.5714 - val_acc: 0.7753\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5255 - acc: 0.7664 - val_loss: 0.5590 - val_acc: 0.7528\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4980 - acc: 0.7932 - val_loss: 0.5506 - val_acc: 0.7472\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4773 - acc: 0.7853 - val_loss: 0.5372 - val_acc: 0.7697\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4432 - acc: 0.8290 - val_loss: 0.5305 - val_acc: 0.7753\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4183 - acc: 0.8509 - val_loss: 0.5300 - val_acc: 0.7753\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3882 - acc: 0.8688 - val_loss: 0.5528 - val_acc: 0.7640\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3577 - acc: 0.8797 - val_loss: 0.5541 - val_acc: 0.7697\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3248 - acc: 0.9046 - val_loss: 0.5684 - val_acc: 0.7640\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3169 - acc: 0.8986 - val_loss: 0.5778 - val_acc: 0.7753\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.2971 - acc: 0.9036 - val_loss: 0.6053 - val_acc: 0.7697\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2732 - acc: 0.9195 - val_loss: 0.6347 - val_acc: 0.7753\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2558 - acc: 0.9254 - val_loss: 0.6619 - val_acc: 0.7809\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.2488 - acc: 0.9334 - val_loss: 0.6863 - val_acc: 0.7753\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2268 - acc: 0.9463 - val_loss: 0.6974 - val_acc: 0.7921\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2147 - acc: 0.9463 - val_loss: 0.7259 - val_acc: 0.7978\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1935 - acc: 0.9642 - val_loss: 0.7500 - val_acc: 0.7865\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1880 - acc: 0.9583 - val_loss: 0.8020 - val_acc: 0.7809\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1848 - acc: 0.9493 - val_loss: 0.8303 - val_acc: 0.7865\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1752 - acc: 0.9652 - val_loss: 0.8479 - val_acc: 0.7865\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1589 - acc: 0.9692 - val_loss: 0.8820 - val_acc: 0.7921\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1533 - acc: 0.9632 - val_loss: 0.9266 - val_acc: 0.7865\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1390 - acc: 0.9722 - val_loss: 0.9640 - val_acc: 0.7865\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1290 - acc: 0.9821 - val_loss: 0.9964 - val_acc: 0.7865\n",
      "Accuracy: 0.8225655256905258, Precision: 0.8229019741823631, Recall: 0.8225655256905258, F1-score: 0.8222829650011975\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',False,type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 6s 6ms/step - loss: 0.6928 - acc: 0.5174 - val_loss: 0.6889 - val_acc: 0.7022\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6860 - acc: 0.6030 - val_loss: 0.6823 - val_acc: 0.6236\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6821 - acc: 0.6109 - val_loss: 0.6751 - val_acc: 0.6348\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6766 - acc: 0.6179 - val_loss: 0.6654 - val_acc: 0.6292\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6635 - acc: 0.6488 - val_loss: 0.6525 - val_acc: 0.6404\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6530 - acc: 0.6697 - val_loss: 0.6360 - val_acc: 0.6517\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6349 - acc: 0.6925 - val_loss: 0.6141 - val_acc: 0.6573\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.6119 - acc: 0.7363 - val_loss: 0.5859 - val_acc: 0.7191\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5809 - acc: 0.7881 - val_loss: 0.5516 - val_acc: 0.7697\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.5487 - acc: 0.8368 - val_loss: 0.5127 - val_acc: 0.8090\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.5002 - acc: 0.8507 - val_loss: 0.4710 - val_acc: 0.8258\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4449 - acc: 0.8935 - val_loss: 0.4289 - val_acc: 0.8652\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.4017 - acc: 0.9055 - val_loss: 0.3907 - val_acc: 0.9101\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3639 - acc: 0.9035 - val_loss: 0.3605 - val_acc: 0.9101\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.3206 - acc: 0.9224 - val_loss: 0.3369 - val_acc: 0.9101\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2796 - acc: 0.9333 - val_loss: 0.3186 - val_acc: 0.9101\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.2449 - acc: 0.9453 - val_loss: 0.3037 - val_acc: 0.9157\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.2199 - acc: 0.9502 - val_loss: 0.2949 - val_acc: 0.9157\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1811 - acc: 0.9672 - val_loss: 0.2877 - val_acc: 0.9157\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1628 - acc: 0.9662 - val_loss: 0.2833 - val_acc: 0.9157\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 5s 4ms/step - loss: 0.1358 - acc: 0.9771 - val_loss: 0.2803 - val_acc: 0.9157\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1239 - acc: 0.9811 - val_loss: 0.2824 - val_acc: 0.9045\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.1002 - acc: 0.9851 - val_loss: 0.2792 - val_acc: 0.9213\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0901 - acc: 0.9851 - val_loss: 0.2808 - val_acc: 0.9213\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.0801 - acc: 0.9910 - val_loss: 0.2838 - val_acc: 0.9213\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0705 - acc: 0.9940 - val_loss: 0.2855 - val_acc: 0.9213\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0588 - acc: 0.9950 - val_loss: 0.2875 - val_acc: 0.9213\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 4s 4ms/step - loss: 0.0492 - acc: 0.9960 - val_loss: 0.2912 - val_acc: 0.9157\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0480 - acc: 0.9970 - val_loss: 0.2946 - val_acc: 0.9157\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 5s 5ms/step - loss: 0.0418 - acc: 0.9990 - val_loss: 0.2962 - val_acc: 0.9157\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6929 - acc: 0.4821 - val_loss: 0.6930 - val_acc: 0.4382\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6918 - acc: 0.5129 - val_loss: 0.6919 - val_acc: 0.5281\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6904 - acc: 0.5467 - val_loss: 0.6906 - val_acc: 0.5618\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6868 - acc: 0.6014 - val_loss: 0.6890 - val_acc: 0.5787\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 7s 7ms/step - loss: 0.6839 - acc: 0.6233 - val_loss: 0.6873 - val_acc: 0.6404\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 6s 6ms/step - loss: 0.6787 - acc: 0.6700 - val_loss: 0.6847 - val_acc: 0.6348\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6735 - acc: 0.6720 - val_loss: 0.6806 - val_acc: 0.6517\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6659 - acc: 0.7048 - val_loss: 0.6757 - val_acc: 0.6348\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6538 - acc: 0.7127 - val_loss: 0.6687 - val_acc: 0.6404\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6394 - acc: 0.7753 - val_loss: 0.6592 - val_acc: 0.6910\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.6226 - acc: 0.7942 - val_loss: 0.6467 - val_acc: 0.7135\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5912 - acc: 0.8260 - val_loss: 0.6297 - val_acc: 0.7079\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5599 - acc: 0.8549 - val_loss: 0.6148 - val_acc: 0.7135\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.5289 - acc: 0.8807 - val_loss: 0.5934 - val_acc: 0.7191\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4841 - acc: 0.9066 - val_loss: 0.5740 - val_acc: 0.7135\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.4343 - acc: 0.9254 - val_loss: 0.5522 - val_acc: 0.7303\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3858 - acc: 0.9314 - val_loss: 0.5348 - val_acc: 0.7303\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.3297 - acc: 0.9463 - val_loss: 0.5284 - val_acc: 0.7247\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2995 - acc: 0.9503 - val_loss: 0.5138 - val_acc: 0.7360\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.2560 - acc: 0.9612 - val_loss: 0.5091 - val_acc: 0.7303\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.2174 - acc: 0.9732 - val_loss: 0.5066 - val_acc: 0.7416\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1900 - acc: 0.9761 - val_loss: 0.5019 - val_acc: 0.7472\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 5s 4ms/step - loss: 0.1588 - acc: 0.9831 - val_loss: 0.5163 - val_acc: 0.7416\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1368 - acc: 0.9851 - val_loss: 0.5197 - val_acc: 0.7640\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1188 - acc: 0.9881 - val_loss: 0.5332 - val_acc: 0.7584\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.1016 - acc: 0.9901 - val_loss: 0.5397 - val_acc: 0.7697\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.0875 - acc: 0.9960 - val_loss: 0.5473 - val_acc: 0.7809\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.0802 - acc: 0.9960 - val_loss: 0.5631 - val_acc: 0.7753\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 5s 5ms/step - loss: 0.0703 - acc: 0.9930 - val_loss: 0.5844 - val_acc: 0.7528\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 4s 4ms/step - loss: 0.0601 - acc: 0.9930 - val_loss: 0.5846 - val_acc: 0.7697\n",
      "Accuracy: 0.8082059896963742, Precision: 0.8086653090850501, Recall: 0.8082059896963742, F1-score: 0.8080407047235154\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'feed_forward_nn',False,type='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10000, 1)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 10000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 9998, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9998, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 9996, 64)          24640     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 9996, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4998, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 319872)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 319873    \n",
      "=================================================================\n",
      "Total params: 345,025\n",
      "Trainable params: 345,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/10\n",
      "1005/1005 [==============================] - 401s 399ms/step - loss: 0.6800 - accuracy: 0.5821 - val_loss: 0.6485 - val_accuracy: 0.8708\n",
      "Epoch 2/10\n",
      "1005/1005 [==============================] - 369s 367ms/step - loss: 0.5797 - accuracy: 0.7373 - val_loss: 0.4954 - val_accuracy: 0.8258\n",
      "Epoch 3/10\n",
      "1005/1005 [==============================] - 223s 222ms/step - loss: 0.4669 - accuracy: 0.7642 - val_loss: 0.3755 - val_accuracy: 0.9101\n",
      "Epoch 4/10\n",
      "1005/1005 [==============================] - 318s 317ms/step - loss: 0.3836 - accuracy: 0.7990 - val_loss: 0.3625 - val_accuracy: 0.9045\n",
      "Epoch 5/10\n",
      "1005/1005 [==============================] - 232s 231ms/step - loss: 0.3068 - accuracy: 0.8338 - val_loss: 0.3675 - val_accuracy: 0.8933\n",
      "Epoch 6/10\n",
      "1005/1005 [==============================] - 277s 275ms/step - loss: 0.2504 - accuracy: 0.8527 - val_loss: 0.3385 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "1005/1005 [==============================] - 232s 231ms/step - loss: 0.2374 - accuracy: 0.8627 - val_loss: 0.3580 - val_accuracy: 0.8820\n",
      "Epoch 8/10\n",
      "1005/1005 [==============================] - 295s 294ms/step - loss: 0.2404 - accuracy: 0.8478 - val_loss: 0.3685 - val_accuracy: 0.8708\n",
      "Epoch 9/10\n",
      "1005/1005 [==============================] - 199s 198ms/step - loss: 0.2338 - accuracy: 0.8627 - val_loss: 0.3749 - val_accuracy: 0.8708\n",
      "Epoch 10/10\n",
      "1005/1005 [==============================] - 194s 193ms/step - loss: 0.2234 - accuracy: 0.8677 - val_loss: 0.3818 - val_accuracy: 0.8596\n",
      "1184/1184 [==============================] - 57s 48ms/step\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 10000, 1)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 10000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 9998, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 9998, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 9996, 64)          24640     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 9996, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4998, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 319872)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 319873    \n",
      "=================================================================\n",
      "Total params: 345,025\n",
      "Trainable params: 345,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/10\n",
      "1006/1006 [==============================] - 202s 201ms/step - loss: 0.6839 - accuracy: 0.5736 - val_loss: 0.6678 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "1006/1006 [==============================] - 200s 199ms/step - loss: 0.5884 - accuracy: 0.7107 - val_loss: 0.5834 - val_accuracy: 0.7697\n",
      "Epoch 3/10\n",
      "1006/1006 [==============================] - 213s 211ms/step - loss: 0.4547 - accuracy: 0.7664 - val_loss: 0.5451 - val_accuracy: 0.7416\n",
      "Epoch 4/10\n",
      "1006/1006 [==============================] - 198s 197ms/step - loss: 0.3917 - accuracy: 0.7863 - val_loss: 0.5356 - val_accuracy: 0.7753\n",
      "Epoch 5/10\n",
      "1006/1006 [==============================] - 184s 182ms/step - loss: 0.3360 - accuracy: 0.7972 - val_loss: 0.5272 - val_accuracy: 0.7416\n",
      "Epoch 6/10\n",
      "1006/1006 [==============================] - 181s 180ms/step - loss: 0.2992 - accuracy: 0.8211 - val_loss: 0.5266 - val_accuracy: 0.7472\n",
      "Epoch 7/10\n",
      "1006/1006 [==============================] - 192s 190ms/step - loss: 0.3186 - accuracy: 0.8062 - val_loss: 0.5164 - val_accuracy: 0.7809\n",
      "Epoch 8/10\n",
      "1006/1006 [==============================] - 256s 255ms/step - loss: 0.3086 - accuracy: 0.8111 - val_loss: 0.5266 - val_accuracy: 0.7416\n",
      "Epoch 9/10\n",
      "1006/1006 [==============================] - 415s 412ms/step - loss: 0.2914 - accuracy: 0.8171 - val_loss: 0.5683 - val_accuracy: 0.7416\n",
      "Epoch 10/10\n",
      "1006/1006 [==============================] - 305s 303ms/step - loss: 0.3006 - accuracy: 0.8062 - val_loss: 0.5647 - val_accuracy: 0.7416\n",
      "1183/1183 [==============================] - 62s 53ms/step\n",
      "Accuracy: 0.7587661493911494, Precision: 0.75901522694407, Recall: 0.7587661493911494, F1-score: 0.7573788490172977\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',True,type=\"tfidf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 9s 9ms/step - loss: 0.7378 - acc: 0.5224 - val_loss: 0.6414 - val_acc: 0.6854\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6764 - acc: 0.5841 - val_loss: 0.6079 - val_acc: 0.8258\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6517 - acc: 0.6179 - val_loss: 0.5778 - val_acc: 0.8539\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6299 - acc: 0.6458 - val_loss: 0.5499 - val_acc: 0.8427\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5939 - acc: 0.6687 - val_loss: 0.5164 - val_acc: 0.8596\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5712 - acc: 0.6915 - val_loss: 0.4792 - val_acc: 0.8764\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5544 - acc: 0.7363 - val_loss: 0.4493 - val_acc: 0.8876\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5141 - acc: 0.7622 - val_loss: 0.4234 - val_acc: 0.8876\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4858 - acc: 0.7871 - val_loss: 0.3981 - val_acc: 0.8876\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4817 - acc: 0.7821 - val_loss: 0.3706 - val_acc: 0.8989\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4444 - acc: 0.8139 - val_loss: 0.3482 - val_acc: 0.9045\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4248 - acc: 0.8269 - val_loss: 0.3313 - val_acc: 0.9101\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3893 - acc: 0.8368 - val_loss: 0.3183 - val_acc: 0.8989\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3684 - acc: 0.8547 - val_loss: 0.3040 - val_acc: 0.9101\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3332 - acc: 0.8806 - val_loss: 0.2921 - val_acc: 0.9101\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3281 - acc: 0.8786 - val_loss: 0.2841 - val_acc: 0.9045\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2939 - acc: 0.8905 - val_loss: 0.2886 - val_acc: 0.8820\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2744 - acc: 0.9015 - val_loss: 0.2817 - val_acc: 0.8989\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2558 - acc: 0.9114 - val_loss: 0.2776 - val_acc: 0.8876\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2498 - acc: 0.9065 - val_loss: 0.2768 - val_acc: 0.8876\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2192 - acc: 0.9214 - val_loss: 0.2832 - val_acc: 0.8933\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1963 - acc: 0.9333 - val_loss: 0.2835 - val_acc: 0.8876\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1820 - acc: 0.9483 - val_loss: 0.2856 - val_acc: 0.8933\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1758 - acc: 0.9483 - val_loss: 0.2913 - val_acc: 0.8876\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1606 - acc: 0.9483 - val_loss: 0.2943 - val_acc: 0.8933\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1390 - acc: 0.9592 - val_loss: 0.2988 - val_acc: 0.8764\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1429 - acc: 0.9612 - val_loss: 0.3043 - val_acc: 0.8708\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1320 - acc: 0.9612 - val_loss: 0.3088 - val_acc: 0.8708\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1195 - acc: 0.9632 - val_loss: 0.3153 - val_acc: 0.8708\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.1049 - acc: 0.9771 - val_loss: 0.3202 - val_acc: 0.8764\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 10s 10ms/step - loss: 0.7179 - acc: 0.5109 - val_loss: 0.6889 - val_acc: 0.5449\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7059 - acc: 0.5308 - val_loss: 0.6719 - val_acc: 0.6236\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6717 - acc: 0.5984 - val_loss: 0.6595 - val_acc: 0.6742\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6589 - acc: 0.6133 - val_loss: 0.6478 - val_acc: 0.6966\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6423 - acc: 0.6292 - val_loss: 0.6349 - val_acc: 0.7022\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6240 - acc: 0.6799 - val_loss: 0.6152 - val_acc: 0.7191\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6028 - acc: 0.7008 - val_loss: 0.5973 - val_acc: 0.7303\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5872 - acc: 0.7038 - val_loss: 0.5838 - val_acc: 0.7360\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5477 - acc: 0.7475 - val_loss: 0.5701 - val_acc: 0.7416\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5426 - acc: 0.7455 - val_loss: 0.5570 - val_acc: 0.7472\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5085 - acc: 0.7744 - val_loss: 0.5481 - val_acc: 0.7584\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4980 - acc: 0.7952 - val_loss: 0.5442 - val_acc: 0.7528\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4722 - acc: 0.8101 - val_loss: 0.5434 - val_acc: 0.7640\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4589 - acc: 0.8052 - val_loss: 0.5360 - val_acc: 0.7640\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4242 - acc: 0.8489 - val_loss: 0.5348 - val_acc: 0.7640\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4115 - acc: 0.8489 - val_loss: 0.5386 - val_acc: 0.7640\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3897 - acc: 0.8479 - val_loss: 0.5477 - val_acc: 0.7640\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3634 - acc: 0.8658 - val_loss: 0.5502 - val_acc: 0.7640\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3680 - acc: 0.8588 - val_loss: 0.5607 - val_acc: 0.7753\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3368 - acc: 0.8867 - val_loss: 0.5701 - val_acc: 0.7753\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3339 - acc: 0.8887 - val_loss: 0.5824 - val_acc: 0.7697\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3173 - acc: 0.8797 - val_loss: 0.5969 - val_acc: 0.7753\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2946 - acc: 0.9056 - val_loss: 0.6066 - val_acc: 0.7865\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2854 - acc: 0.9056 - val_loss: 0.6222 - val_acc: 0.7865\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2844 - acc: 0.9006 - val_loss: 0.6439 - val_acc: 0.7865\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2731 - acc: 0.8966 - val_loss: 0.6670 - val_acc: 0.7809\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2564 - acc: 0.9145 - val_loss: 0.6943 - val_acc: 0.7753\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2570 - acc: 0.9115 - val_loss: 0.7087 - val_acc: 0.7865\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2357 - acc: 0.9225 - val_loss: 0.7212 - val_acc: 0.7978\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.2364 - acc: 0.9185 - val_loss: 0.7399 - val_acc: 0.7921\n",
      "Accuracy: 0.8284826854538393, Precision: 0.8289447074370717, Recall: 0.8284826854538393\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',True,type=\"binary\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 9s 9ms/step - loss: 0.9844 - acc: 0.5284 - val_loss: 0.6318 - val_acc: 0.5787\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.8529 - acc: 0.5602 - val_loss: 0.5953 - val_acc: 0.6348\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7856 - acc: 0.5602 - val_loss: 0.5781 - val_acc: 0.6966\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7222 - acc: 0.5990 - val_loss: 0.5716 - val_acc: 0.7809\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6873 - acc: 0.6249 - val_loss: 0.5620 - val_acc: 0.7753\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6810 - acc: 0.6408 - val_loss: 0.5494 - val_acc: 0.7921\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6760 - acc: 0.6647 - val_loss: 0.5366 - val_acc: 0.8202\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6267 - acc: 0.6637 - val_loss: 0.5244 - val_acc: 0.8427\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5822 - acc: 0.6915 - val_loss: 0.5116 - val_acc: 0.8315\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5934 - acc: 0.6806 - val_loss: 0.4993 - val_acc: 0.8427\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5930 - acc: 0.6866 - val_loss: 0.4848 - val_acc: 0.8483\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5434 - acc: 0.7303 - val_loss: 0.4719 - val_acc: 0.8596\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5064 - acc: 0.7532 - val_loss: 0.4579 - val_acc: 0.8539\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5071 - acc: 0.7612 - val_loss: 0.4491 - val_acc: 0.8820\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5089 - acc: 0.7423 - val_loss: 0.4355 - val_acc: 0.8764\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5366 - acc: 0.7522 - val_loss: 0.4230 - val_acc: 0.8989\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4744 - acc: 0.7791 - val_loss: 0.4158 - val_acc: 0.9045\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4468 - acc: 0.7980 - val_loss: 0.4050 - val_acc: 0.9045\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4577 - acc: 0.7940 - val_loss: 0.3898 - val_acc: 0.9045\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4512 - acc: 0.7781 - val_loss: 0.3720 - val_acc: 0.9045\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4053 - acc: 0.8189 - val_loss: 0.3607 - val_acc: 0.9101\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3908 - acc: 0.8259 - val_loss: 0.3535 - val_acc: 0.9101\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3720 - acc: 0.8458 - val_loss: 0.3523 - val_acc: 0.9101\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3727 - acc: 0.8438 - val_loss: 0.3412 - val_acc: 0.9045\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3789 - acc: 0.8388 - val_loss: 0.3360 - val_acc: 0.9157\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3432 - acc: 0.8677 - val_loss: 0.3356 - val_acc: 0.9157\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3356 - acc: 0.8677 - val_loss: 0.3284 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3127 - acc: 0.8766 - val_loss: 0.3208 - val_acc: 0.9157\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3214 - acc: 0.8736 - val_loss: 0.3188 - val_acc: 0.9101\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2939 - acc: 0.8876 - val_loss: 0.3237 - val_acc: 0.9157\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 9s 9ms/step - loss: 0.9195 - acc: 0.5338 - val_loss: 0.6684 - val_acc: 0.5787\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.8362 - acc: 0.5746 - val_loss: 0.6380 - val_acc: 0.6517\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7785 - acc: 0.5924 - val_loss: 0.6286 - val_acc: 0.6966\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7112 - acc: 0.6064 - val_loss: 0.6179 - val_acc: 0.7135\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7097 - acc: 0.5984 - val_loss: 0.6087 - val_acc: 0.7079\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6613 - acc: 0.6571 - val_loss: 0.5988 - val_acc: 0.6966\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6192 - acc: 0.6730 - val_loss: 0.5885 - val_acc: 0.7135\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6272 - acc: 0.6928 - val_loss: 0.5801 - val_acc: 0.7135\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6336 - acc: 0.6740 - val_loss: 0.5735 - val_acc: 0.7303\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5971 - acc: 0.6799 - val_loss: 0.5675 - val_acc: 0.7303\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5534 - acc: 0.7217 - val_loss: 0.5596 - val_acc: 0.7303\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5612 - acc: 0.7187 - val_loss: 0.5552 - val_acc: 0.7360\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5571 - acc: 0.7296 - val_loss: 0.5506 - val_acc: 0.7360\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5285 - acc: 0.7505 - val_loss: 0.5433 - val_acc: 0.7360\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5480 - acc: 0.7565 - val_loss: 0.5422 - val_acc: 0.7360\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5095 - acc: 0.7664 - val_loss: 0.5359 - val_acc: 0.7472\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4897 - acc: 0.7873 - val_loss: 0.5371 - val_acc: 0.7472\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4740 - acc: 0.8022 - val_loss: 0.5348 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5005 - acc: 0.7793 - val_loss: 0.5326 - val_acc: 0.7472\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4555 - acc: 0.8082 - val_loss: 0.5305 - val_acc: 0.7472\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4606 - acc: 0.8151 - val_loss: 0.5357 - val_acc: 0.7416\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4621 - acc: 0.7952 - val_loss: 0.5368 - val_acc: 0.7472\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4169 - acc: 0.8380 - val_loss: 0.5385 - val_acc: 0.7472\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4204 - acc: 0.8290 - val_loss: 0.5466 - val_acc: 0.7528\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4189 - acc: 0.8330 - val_loss: 0.5547 - val_acc: 0.7472\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4124 - acc: 0.8410 - val_loss: 0.5576 - val_acc: 0.7416\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3821 - acc: 0.8429 - val_loss: 0.5557 - val_acc: 0.7472\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3872 - acc: 0.8509 - val_loss: 0.5607 - val_acc: 0.7472\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3803 - acc: 0.8608 - val_loss: 0.5737 - val_acc: 0.7472\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3763 - acc: 0.8549 - val_loss: 0.5846 - val_acc: 0.7472\n",
      "Accuracy: 0.8039787330652715, Precision: 0.8041647961930565, Recall: 0.8039787330652715\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',True,type=\"counts\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 9s 9ms/step - loss: 0.9786 - acc: 0.5154 - val_loss: 0.6307 - val_acc: 0.6180\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.8354 - acc: 0.5502 - val_loss: 0.5886 - val_acc: 0.7135\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7559 - acc: 0.5891 - val_loss: 0.5610 - val_acc: 0.7584\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7241 - acc: 0.6050 - val_loss: 0.5497 - val_acc: 0.7697\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6817 - acc: 0.6308 - val_loss: 0.5369 - val_acc: 0.7865\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6624 - acc: 0.6527 - val_loss: 0.5211 - val_acc: 0.7809\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6527 - acc: 0.6448 - val_loss: 0.5085 - val_acc: 0.8034\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6286 - acc: 0.6756 - val_loss: 0.5027 - val_acc: 0.8202\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5623 - acc: 0.7204 - val_loss: 0.4972 - val_acc: 0.8258\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6079 - acc: 0.7045 - val_loss: 0.4896 - val_acc: 0.8539\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.6975 - val_loss: 0.4742 - val_acc: 0.8539\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5662 - acc: 0.7095 - val_loss: 0.4593 - val_acc: 0.8652\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5417 - acc: 0.7284 - val_loss: 0.4461 - val_acc: 0.8652\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5109 - acc: 0.7701 - val_loss: 0.4344 - val_acc: 0.8708\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5089 - acc: 0.7522 - val_loss: 0.4245 - val_acc: 0.8933\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5147 - acc: 0.7771 - val_loss: 0.4172 - val_acc: 0.8933\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4662 - acc: 0.7970 - val_loss: 0.4101 - val_acc: 0.8933\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4332 - acc: 0.8149 - val_loss: 0.4031 - val_acc: 0.8933\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4377 - acc: 0.8109 - val_loss: 0.3949 - val_acc: 0.8876\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4398 - acc: 0.8090 - val_loss: 0.3805 - val_acc: 0.8876\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4174 - acc: 0.8219 - val_loss: 0.3729 - val_acc: 0.8933\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3995 - acc: 0.8328 - val_loss: 0.3640 - val_acc: 0.8876\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3830 - acc: 0.8478 - val_loss: 0.3632 - val_acc: 0.8989\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3526 - acc: 0.8557 - val_loss: 0.3626 - val_acc: 0.8876\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3422 - acc: 0.8667 - val_loss: 0.3588 - val_acc: 0.8876\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3449 - acc: 0.8647 - val_loss: 0.3550 - val_acc: 0.8876\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3467 - acc: 0.8706 - val_loss: 0.3503 - val_acc: 0.8933\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3172 - acc: 0.8756 - val_loss: 0.3515 - val_acc: 0.8876\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3045 - acc: 0.8816 - val_loss: 0.3476 - val_acc: 0.8989\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2826 - acc: 0.8905 - val_loss: 0.3508 - val_acc: 0.8933\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 11s 10ms/step - loss: 0.9224 - acc: 0.4901 - val_loss: 0.6660 - val_acc: 0.5618\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7847 - acc: 0.5586 - val_loss: 0.6317 - val_acc: 0.6742\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7838 - acc: 0.5527 - val_loss: 0.6170 - val_acc: 0.6798\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7114 - acc: 0.5815 - val_loss: 0.6076 - val_acc: 0.6798\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7044 - acc: 0.5974 - val_loss: 0.5984 - val_acc: 0.7079\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7010 - acc: 0.5736 - val_loss: 0.5927 - val_acc: 0.7079\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6467 - acc: 0.6610 - val_loss: 0.5861 - val_acc: 0.7022\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6521 - acc: 0.6581 - val_loss: 0.5793 - val_acc: 0.7135\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6139 - acc: 0.6590 - val_loss: 0.5741 - val_acc: 0.7247\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5941 - acc: 0.6918 - val_loss: 0.5683 - val_acc: 0.7303\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5519 - acc: 0.7008 - val_loss: 0.5613 - val_acc: 0.7360\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5818 - acc: 0.6879 - val_loss: 0.5565 - val_acc: 0.7247\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5496 - acc: 0.7286 - val_loss: 0.5511 - val_acc: 0.7247\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5363 - acc: 0.7336 - val_loss: 0.5469 - val_acc: 0.7135\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5387 - acc: 0.7435 - val_loss: 0.5416 - val_acc: 0.7247\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5149 - acc: 0.7525 - val_loss: 0.5394 - val_acc: 0.7360\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5090 - acc: 0.7694 - val_loss: 0.5399 - val_acc: 0.7416\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4765 - acc: 0.7962 - val_loss: 0.5424 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5038 - acc: 0.7783 - val_loss: 0.5436 - val_acc: 0.7416\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4701 - acc: 0.8181 - val_loss: 0.5399 - val_acc: 0.7528\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4504 - acc: 0.8231 - val_loss: 0.5408 - val_acc: 0.7528\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4471 - acc: 0.8002 - val_loss: 0.5439 - val_acc: 0.7584\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4217 - acc: 0.8290 - val_loss: 0.5466 - val_acc: 0.7584\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4308 - acc: 0.8151 - val_loss: 0.5549 - val_acc: 0.7472\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4188 - acc: 0.8419 - val_loss: 0.5589 - val_acc: 0.7528\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4059 - acc: 0.8380 - val_loss: 0.5639 - val_acc: 0.7472\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3882 - acc: 0.8439 - val_loss: 0.5682 - val_acc: 0.7640\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3956 - acc: 0.8439 - val_loss: 0.5694 - val_acc: 0.7584\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3890 - acc: 0.8628 - val_loss: 0.5703 - val_acc: 0.7640\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3703 - acc: 0.8509 - val_loss: 0.5795 - val_acc: 0.7697\n",
      "Accuracy: 0.8060902195517581, Precision: 0.8064283724096457, Recall: 0.8060902195517581\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',False,type=\"counts\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 10s 10ms/step - loss: 0.9786 - acc: 0.5154 - val_loss: 0.6307 - val_acc: 0.6180\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.8354 - acc: 0.5502 - val_loss: 0.5886 - val_acc: 0.7135\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7559 - acc: 0.5891 - val_loss: 0.5610 - val_acc: 0.7584\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7241 - acc: 0.6050 - val_loss: 0.5497 - val_acc: 0.7697\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6817 - acc: 0.6308 - val_loss: 0.5369 - val_acc: 0.7865\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6624 - acc: 0.6527 - val_loss: 0.5211 - val_acc: 0.7809\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6527 - acc: 0.6448 - val_loss: 0.5085 - val_acc: 0.8034\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6286 - acc: 0.6756 - val_loss: 0.5027 - val_acc: 0.8202\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5623 - acc: 0.7204 - val_loss: 0.4972 - val_acc: 0.8258\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6079 - acc: 0.7045 - val_loss: 0.4896 - val_acc: 0.8539\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.6975 - val_loss: 0.4742 - val_acc: 0.8539\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5662 - acc: 0.7095 - val_loss: 0.4593 - val_acc: 0.8652\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5417 - acc: 0.7284 - val_loss: 0.4461 - val_acc: 0.8652\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5109 - acc: 0.7701 - val_loss: 0.4344 - val_acc: 0.8708\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5089 - acc: 0.7522 - val_loss: 0.4245 - val_acc: 0.8933\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5147 - acc: 0.7771 - val_loss: 0.4172 - val_acc: 0.8933\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4662 - acc: 0.7970 - val_loss: 0.4101 - val_acc: 0.8933\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4332 - acc: 0.8149 - val_loss: 0.4031 - val_acc: 0.8933\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4377 - acc: 0.8109 - val_loss: 0.3949 - val_acc: 0.8876\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4398 - acc: 0.8090 - val_loss: 0.3805 - val_acc: 0.8876\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4174 - acc: 0.8219 - val_loss: 0.3729 - val_acc: 0.8933\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3995 - acc: 0.8328 - val_loss: 0.3640 - val_acc: 0.8876\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3830 - acc: 0.8478 - val_loss: 0.3632 - val_acc: 0.8989\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3526 - acc: 0.8557 - val_loss: 0.3626 - val_acc: 0.8876\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3422 - acc: 0.8667 - val_loss: 0.3588 - val_acc: 0.8876\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3449 - acc: 0.8647 - val_loss: 0.3550 - val_acc: 0.8876\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3467 - acc: 0.8706 - val_loss: 0.3503 - val_acc: 0.8933\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3172 - acc: 0.8756 - val_loss: 0.3515 - val_acc: 0.8876\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3045 - acc: 0.8816 - val_loss: 0.3476 - val_acc: 0.8989\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2826 - acc: 0.8905 - val_loss: 0.3508 - val_acc: 0.8933\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 10s 10ms/step - loss: 0.9222 - acc: 0.4901 - val_loss: 0.6661 - val_acc: 0.5730\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7845 - acc: 0.5586 - val_loss: 0.6318 - val_acc: 0.6742\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7835 - acc: 0.5547 - val_loss: 0.6175 - val_acc: 0.6854\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7115 - acc: 0.5835 - val_loss: 0.6082 - val_acc: 0.6854\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7042 - acc: 0.5964 - val_loss: 0.5986 - val_acc: 0.7079\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7010 - acc: 0.5755 - val_loss: 0.5928 - val_acc: 0.7079\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6466 - acc: 0.6600 - val_loss: 0.5866 - val_acc: 0.7022\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6524 - acc: 0.6581 - val_loss: 0.5803 - val_acc: 0.7191\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6141 - acc: 0.6620 - val_loss: 0.5751 - val_acc: 0.7303\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5924 - acc: 0.6859 - val_loss: 0.5691 - val_acc: 0.7247\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5516 - acc: 0.7008 - val_loss: 0.5619 - val_acc: 0.7360\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5811 - acc: 0.6809 - val_loss: 0.5566 - val_acc: 0.7303\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5491 - acc: 0.7306 - val_loss: 0.5513 - val_acc: 0.7191\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5373 - acc: 0.7376 - val_loss: 0.5470 - val_acc: 0.7191\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5405 - acc: 0.7435 - val_loss: 0.5418 - val_acc: 0.7247\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5169 - acc: 0.7545 - val_loss: 0.5399 - val_acc: 0.7303\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5082 - acc: 0.7714 - val_loss: 0.5403 - val_acc: 0.7360\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4775 - acc: 0.7972 - val_loss: 0.5429 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5021 - acc: 0.7793 - val_loss: 0.5439 - val_acc: 0.7416\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4700 - acc: 0.8181 - val_loss: 0.5401 - val_acc: 0.7528\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4499 - acc: 0.8241 - val_loss: 0.5401 - val_acc: 0.7528\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4478 - acc: 0.8012 - val_loss: 0.5435 - val_acc: 0.7528\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4214 - acc: 0.8270 - val_loss: 0.5457 - val_acc: 0.7584\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4308 - acc: 0.8181 - val_loss: 0.5554 - val_acc: 0.7528\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4193 - acc: 0.8410 - val_loss: 0.5598 - val_acc: 0.7528\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4066 - acc: 0.8400 - val_loss: 0.5638 - val_acc: 0.7472\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3879 - acc: 0.8469 - val_loss: 0.5671 - val_acc: 0.7640\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3954 - acc: 0.8439 - val_loss: 0.5691 - val_acc: 0.7640\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3893 - acc: 0.8579 - val_loss: 0.5712 - val_acc: 0.7697\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3701 - acc: 0.8509 - val_loss: 0.5815 - val_acc: 0.7697\n",
      "Accuracy: 0.8060902195517581, Precision: 0.8064213069400292, Recall: 0.8060902195517581\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',False,type=\"tfidf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1005/1005 [==============================] - 9s 9ms/step - loss: 0.9786 - acc: 0.5154 - val_loss: 0.6307 - val_acc: 0.6180\n",
      "Epoch 2/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.8354 - acc: 0.5502 - val_loss: 0.5886 - val_acc: 0.7135\n",
      "Epoch 3/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7559 - acc: 0.5891 - val_loss: 0.5610 - val_acc: 0.7584\n",
      "Epoch 4/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.7241 - acc: 0.6050 - val_loss: 0.5497 - val_acc: 0.7697\n",
      "Epoch 5/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6817 - acc: 0.6308 - val_loss: 0.5369 - val_acc: 0.7865\n",
      "Epoch 6/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6624 - acc: 0.6527 - val_loss: 0.5211 - val_acc: 0.7809\n",
      "Epoch 7/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6527 - acc: 0.6448 - val_loss: 0.5085 - val_acc: 0.8034\n",
      "Epoch 8/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6286 - acc: 0.6756 - val_loss: 0.5027 - val_acc: 0.8202\n",
      "Epoch 9/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5623 - acc: 0.7204 - val_loss: 0.4972 - val_acc: 0.8258\n",
      "Epoch 10/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.6079 - acc: 0.7045 - val_loss: 0.4896 - val_acc: 0.8539\n",
      "Epoch 11/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5841 - acc: 0.6975 - val_loss: 0.4742 - val_acc: 0.8539\n",
      "Epoch 12/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5662 - acc: 0.7095 - val_loss: 0.4593 - val_acc: 0.8652\n",
      "Epoch 13/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5417 - acc: 0.7284 - val_loss: 0.4461 - val_acc: 0.8652\n",
      "Epoch 14/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5109 - acc: 0.7701 - val_loss: 0.4344 - val_acc: 0.8708\n",
      "Epoch 15/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5089 - acc: 0.7522 - val_loss: 0.4245 - val_acc: 0.8933\n",
      "Epoch 16/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.5147 - acc: 0.7771 - val_loss: 0.4172 - val_acc: 0.8933\n",
      "Epoch 17/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4662 - acc: 0.7970 - val_loss: 0.4101 - val_acc: 0.8933\n",
      "Epoch 18/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4332 - acc: 0.8149 - val_loss: 0.4031 - val_acc: 0.8933\n",
      "Epoch 19/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4377 - acc: 0.8109 - val_loss: 0.3949 - val_acc: 0.8876\n",
      "Epoch 20/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4398 - acc: 0.8090 - val_loss: 0.3805 - val_acc: 0.8876\n",
      "Epoch 21/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.4174 - acc: 0.8219 - val_loss: 0.3729 - val_acc: 0.8933\n",
      "Epoch 22/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3995 - acc: 0.8328 - val_loss: 0.3640 - val_acc: 0.8876\n",
      "Epoch 23/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3830 - acc: 0.8478 - val_loss: 0.3632 - val_acc: 0.8989\n",
      "Epoch 24/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3526 - acc: 0.8557 - val_loss: 0.3626 - val_acc: 0.8876\n",
      "Epoch 25/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3422 - acc: 0.8667 - val_loss: 0.3588 - val_acc: 0.8876\n",
      "Epoch 26/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3449 - acc: 0.8647 - val_loss: 0.3550 - val_acc: 0.8876\n",
      "Epoch 27/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3467 - acc: 0.8706 - val_loss: 0.3503 - val_acc: 0.8933\n",
      "Epoch 28/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3172 - acc: 0.8756 - val_loss: 0.3515 - val_acc: 0.8876\n",
      "Epoch 29/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.3045 - acc: 0.8816 - val_loss: 0.3476 - val_acc: 0.8989\n",
      "Epoch 30/30\n",
      "1005/1005 [==============================] - 1s 1ms/step - loss: 0.2826 - acc: 0.8905 - val_loss: 0.3508 - val_acc: 0.8933\n",
      "Train on 1006 samples, validate on 178 samples\n",
      "Epoch 1/30\n",
      "1006/1006 [==============================] - 11s 10ms/step - loss: 0.9222 - acc: 0.4901 - val_loss: 0.6660 - val_acc: 0.5674\n",
      "Epoch 2/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7846 - acc: 0.5577 - val_loss: 0.6318 - val_acc: 0.6742\n",
      "Epoch 3/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7835 - acc: 0.5527 - val_loss: 0.6172 - val_acc: 0.6854\n",
      "Epoch 4/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7112 - acc: 0.5835 - val_loss: 0.6078 - val_acc: 0.6854\n",
      "Epoch 5/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7043 - acc: 0.5974 - val_loss: 0.5983 - val_acc: 0.7079\n",
      "Epoch 6/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.7011 - acc: 0.5746 - val_loss: 0.5925 - val_acc: 0.7079\n",
      "Epoch 7/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6463 - acc: 0.6581 - val_loss: 0.5860 - val_acc: 0.6966\n",
      "Epoch 8/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6520 - acc: 0.6571 - val_loss: 0.5798 - val_acc: 0.7135\n",
      "Epoch 9/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.6149 - acc: 0.6571 - val_loss: 0.5744 - val_acc: 0.7303\n",
      "Epoch 10/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5927 - acc: 0.6859 - val_loss: 0.5681 - val_acc: 0.7191\n",
      "Epoch 11/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5522 - acc: 0.7008 - val_loss: 0.5616 - val_acc: 0.7360\n",
      "Epoch 12/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5804 - acc: 0.6849 - val_loss: 0.5562 - val_acc: 0.7303\n",
      "Epoch 13/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5488 - acc: 0.7326 - val_loss: 0.5513 - val_acc: 0.7191\n",
      "Epoch 14/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5365 - acc: 0.7396 - val_loss: 0.5472 - val_acc: 0.7191\n",
      "Epoch 15/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5392 - acc: 0.7435 - val_loss: 0.5417 - val_acc: 0.7247\n",
      "Epoch 16/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5169 - acc: 0.7545 - val_loss: 0.5390 - val_acc: 0.7247\n",
      "Epoch 17/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5096 - acc: 0.7753 - val_loss: 0.5393 - val_acc: 0.7360\n",
      "Epoch 18/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4771 - acc: 0.7942 - val_loss: 0.5413 - val_acc: 0.7416\n",
      "Epoch 19/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.5032 - acc: 0.7734 - val_loss: 0.5423 - val_acc: 0.7472\n",
      "Epoch 20/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4694 - acc: 0.8181 - val_loss: 0.5387 - val_acc: 0.7528\n",
      "Epoch 21/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4500 - acc: 0.8231 - val_loss: 0.5398 - val_acc: 0.7528\n",
      "Epoch 22/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4468 - acc: 0.8022 - val_loss: 0.5432 - val_acc: 0.7528\n",
      "Epoch 23/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4201 - acc: 0.8310 - val_loss: 0.5464 - val_acc: 0.7528\n",
      "Epoch 24/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4307 - acc: 0.8111 - val_loss: 0.5551 - val_acc: 0.7584\n",
      "Epoch 25/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4191 - acc: 0.8429 - val_loss: 0.5591 - val_acc: 0.7584\n",
      "Epoch 26/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.4062 - acc: 0.8410 - val_loss: 0.5633 - val_acc: 0.7472\n",
      "Epoch 27/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3871 - acc: 0.8469 - val_loss: 0.5667 - val_acc: 0.7584\n",
      "Epoch 28/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3950 - acc: 0.8419 - val_loss: 0.5679 - val_acc: 0.7584\n",
      "Epoch 29/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3889 - acc: 0.8598 - val_loss: 0.5694 - val_acc: 0.7640\n",
      "Epoch 30/30\n",
      "1006/1006 [==============================] - 1s 1ms/step - loss: 0.3701 - acc: 0.8519 - val_loss: 0.5784 - val_acc: 0.7697\n",
      "Accuracy: 0.8060902195517581, Precision: 0.8064392145178523, Recall: 0.8060902195517581\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'cnn',False,type=\"binary\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1514 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1514/1514 [==============================] - 406s 268ms/step - loss: 0.6931 - acc: 0.5119 - val_loss: 0.6927 - val_acc: 0.5620\n",
      "Epoch 2/10\n",
      "1514/1514 [==============================] - 394s 260ms/step - loss: 0.6929 - acc: 0.5310 - val_loss: 0.6923 - val_acc: 0.5620\n",
      "Epoch 3/10\n",
      "1514/1514 [==============================] - 398s 263ms/step - loss: 0.6926 - acc: 0.5297 - val_loss: 0.6918 - val_acc: 0.5620\n",
      "Epoch 4/10\n",
      "1514/1514 [==============================] - 395s 261ms/step - loss: 0.6925 - acc: 0.5297 - val_loss: 0.6916 - val_acc: 0.5620\n",
      "Epoch 5/10\n",
      "1514/1514 [==============================] - 396s 261ms/step - loss: 0.6924 - acc: 0.5297 - val_loss: 0.6913 - val_acc: 0.5620\n",
      "Epoch 6/10\n",
      "1514/1514 [==============================] - 399s 263ms/step - loss: 0.6923 - acc: 0.5297 - val_loss: 0.6911 - val_acc: 0.5620\n",
      "Epoch 7/10\n",
      "1514/1514 [==============================] - 398s 263ms/step - loss: 0.6922 - acc: 0.5297 - val_loss: 0.6909 - val_acc: 0.5620\n",
      "Epoch 8/10\n",
      "1514/1514 [==============================] - 444s 293ms/step - loss: 0.6921 - acc: 0.5297 - val_loss: 0.6907 - val_acc: 0.5620\n",
      "Epoch 9/10\n",
      "1514/1514 [==============================] - 427s 282ms/step - loss: 0.6920 - acc: 0.5297 - val_loss: 0.6903 - val_acc: 0.5620\n",
      "Epoch 10/10\n",
      "1514/1514 [==============================] - 428s 283ms/step - loss: 0.6919 - acc: 0.5297 - val_loss: 0.6900 - val_acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1514 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1514/1514 [==============================] - 418s 276ms/step - loss: 0.6922 - acc: 0.5403 - val_loss: 0.6914 - val_acc: 0.5620\n",
      "Epoch 2/10\n",
      "1514/1514 [==============================] - 398s 263ms/step - loss: 0.6915 - acc: 0.5469 - val_loss: 0.6905 - val_acc: 0.5620\n",
      "Epoch 3/10\n",
      "1514/1514 [==============================] - 398s 263ms/step - loss: 0.6910 - acc: 0.5462 - val_loss: 0.6899 - val_acc: 0.5620\n",
      "Epoch 4/10\n",
      "1514/1514 [==============================] - 395s 261ms/step - loss: 0.6908 - acc: 0.5462 - val_loss: 0.6894 - val_acc: 0.5620\n",
      "Epoch 5/10\n",
      "1514/1514 [==============================] - 402s 265ms/step - loss: 0.6907 - acc: 0.5462 - val_loss: 0.6890 - val_acc: 0.5620\n",
      "Epoch 6/10\n",
      "1514/1514 [==============================] - 397s 262ms/step - loss: 0.6901 - acc: 0.5462 - val_loss: 0.6884 - val_acc: 0.5620\n",
      "Epoch 7/10\n",
      "1514/1514 [==============================] - 396s 261ms/step - loss: 0.6898 - acc: 0.5462 - val_loss: 0.6880 - val_acc: 0.5620\n",
      "Epoch 8/10\n",
      "1514/1514 [==============================] - 396s 262ms/step - loss: 0.6898 - acc: 0.5462 - val_loss: 0.6874 - val_acc: 0.5620\n",
      "Epoch 9/10\n",
      "1514/1514 [==============================] - 436s 288ms/step - loss: 0.6895 - acc: 0.5462 - val_loss: 0.6872 - val_acc: 0.5620\n",
      "Epoch 10/10\n",
      "1514/1514 [==============================] - 422s 279ms/step - loss: 0.6895 - acc: 0.5462 - val_loss: 0.6870 - val_acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1515 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1515/1515 [==============================] - 429s 283ms/step - loss: 0.6932 - acc: 0.5030 - val_loss: 0.6928 - val_acc: 0.5620\n",
      "Epoch 2/10\n",
      "1515/1515 [==============================] - 412s 272ms/step - loss: 0.6926 - acc: 0.5287 - val_loss: 0.6920 - val_acc: 0.5620\n",
      "Epoch 3/10\n",
      "1515/1515 [==============================] - 400s 264ms/step - loss: 0.6925 - acc: 0.5327 - val_loss: 0.6914 - val_acc: 0.5620\n",
      "Epoch 4/10\n",
      "1515/1515 [==============================] - 395s 261ms/step - loss: 0.6922 - acc: 0.5307 - val_loss: 0.6909 - val_acc: 0.5620\n",
      "Epoch 5/10\n",
      "1515/1515 [==============================] - 391s 258ms/step - loss: 0.6923 - acc: 0.5307 - val_loss: 0.6905 - val_acc: 0.5620\n",
      "Epoch 6/10\n",
      "1515/1515 [==============================] - 397s 262ms/step - loss: 0.6918 - acc: 0.5307 - val_loss: 0.6900 - val_acc: 0.5620\n",
      "Epoch 7/10\n",
      "1515/1515 [==============================] - 392s 258ms/step - loss: 0.6916 - acc: 0.5307 - val_loss: 0.6893 - val_acc: 0.5620\n",
      "Epoch 8/10\n",
      "1515/1515 [==============================] - 391s 258ms/step - loss: 0.6917 - acc: 0.5307 - val_loss: 0.6891 - val_acc: 0.5620\n",
      "Epoch 9/10\n",
      "1515/1515 [==============================] - 390s 258ms/step - loss: 0.6917 - acc: 0.5307 - val_loss: 0.6891 - val_acc: 0.5620\n",
      "Epoch 10/10\n",
      "1515/1515 [==============================] - 398s 262ms/step - loss: 0.6915 - acc: 0.5307 - val_loss: 0.6889 - val_acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1515 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1515/1515 [==============================] - 400s 264ms/step - loss: 0.6926 - acc: 0.5248 - val_loss: 0.6918 - val_acc: 0.5620\n",
      "Epoch 2/10\n",
      "1515/1515 [==============================] - 399s 264ms/step - loss: 0.6923 - acc: 0.5380 - val_loss: 0.6910 - val_acc: 0.5620\n",
      "Epoch 3/10\n",
      "1515/1515 [==============================] - 393s 259ms/step - loss: 0.6919 - acc: 0.5366 - val_loss: 0.6904 - val_acc: 0.5620\n",
      "Epoch 4/10\n",
      "1515/1515 [==============================] - 400s 264ms/step - loss: 0.6917 - acc: 0.5366 - val_loss: 0.6899 - val_acc: 0.5620\n",
      "Epoch 5/10\n",
      "1515/1515 [==============================] - 389s 257ms/step - loss: 0.6912 - acc: 0.5366 - val_loss: 0.6893 - val_acc: 0.5620\n",
      "Epoch 6/10\n",
      "1515/1515 [==============================] - 394s 260ms/step - loss: 0.6910 - acc: 0.5366 - val_loss: 0.6889 - val_acc: 0.5620\n",
      "Epoch 7/10\n",
      "1515/1515 [==============================] - 395s 260ms/step - loss: 0.6911 - acc: 0.5366 - val_loss: 0.6885 - val_acc: 0.5620\n",
      "Epoch 8/10\n",
      "1515/1515 [==============================] - 392s 259ms/step - loss: 0.6905 - acc: 0.5366 - val_loss: 0.6881 - val_acc: 0.5620\n",
      "Epoch 9/10\n",
      "1515/1515 [==============================] - 423s 279ms/step - loss: 0.6906 - acc: 0.5366 - val_loss: 0.6877 - val_acc: 0.5620\n",
      "Epoch 10/10\n",
      "1515/1515 [==============================] - 423s 279ms/step - loss: 0.6905 - acc: 0.5366 - val_loss: 0.6874 - val_acc: 0.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1515 samples, validate on 379 samples\n",
      "Epoch 1/10\n",
      "1515/1515 [==============================] - 425s 281ms/step - loss: 0.6927 - acc: 0.5261 - val_loss: 0.6923 - val_acc: 0.5383\n",
      "Epoch 2/10\n",
      "1515/1515 [==============================] - 393s 259ms/step - loss: 0.6925 - acc: 0.5267 - val_loss: 0.6920 - val_acc: 0.5383\n",
      "Epoch 3/10\n",
      "1515/1515 [==============================] - 393s 259ms/step - loss: 0.6924 - acc: 0.5267 - val_loss: 0.6917 - val_acc: 0.5383\n",
      "Epoch 4/10\n",
      "1515/1515 [==============================] - 397s 262ms/step - loss: 0.6922 - acc: 0.5267 - val_loss: 0.6915 - val_acc: 0.5383\n",
      "Epoch 5/10\n",
      "1515/1515 [==============================] - 402s 266ms/step - loss: 0.6919 - acc: 0.5267 - val_loss: 0.6913 - val_acc: 0.5383\n",
      "Epoch 6/10\n",
      "1515/1515 [==============================] - 401s 265ms/step - loss: 0.6921 - acc: 0.5267 - val_loss: 0.6913 - val_acc: 0.5383\n",
      "Epoch 7/10\n",
      "1515/1515 [==============================] - 401s 265ms/step - loss: 0.6920 - acc: 0.5267 - val_loss: 0.6913 - val_acc: 0.5383\n",
      "Epoch 8/10\n",
      "1515/1515 [==============================] - 399s 264ms/step - loss: 0.6921 - acc: 0.5267 - val_loss: 0.6913 - val_acc: 0.5383\n",
      "Accuracy: 0.5386704846522332, Precision: 0.2908887964733716, Recall: 0.5386704846522332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'lstm',True,type='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 946 samples, validate on 237 samples\n",
      "Epoch 1/5\n",
      "946/946 [==============================] - 263s 279ms/step - loss: 0.6905 - acc: 0.5518 - val_loss: 0.6791 - val_acc: 0.5992\n",
      "Epoch 2/5\n",
      "946/946 [==============================] - 258s 272ms/step - loss: 0.6896 - acc: 0.5444 - val_loss: 0.6775 - val_acc: 0.5992\n",
      "Epoch 3/5\n",
      "946/946 [==============================] - 269s 285ms/step - loss: 0.6895 - acc: 0.5444 - val_loss: 0.6814 - val_acc: 0.5992\n",
      "Epoch 4/5\n",
      "946/946 [==============================] - 268s 283ms/step - loss: 0.6904 - acc: 0.5444 - val_loss: 0.6823 - val_acc: 0.5992\n",
      "Epoch 5/5\n",
      "946/946 [==============================] - 259s 274ms/step - loss: 0.6898 - acc: 0.5444 - val_loss: 0.6787 - val_acc: 0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 5000, 10)          500000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 544,602\n",
      "Trainable params: 544,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 947 samples, validate on 237 samples\n",
      "Epoch 1/5\n",
      "947/947 [==============================] - 257s 271ms/step - loss: 0.6929 - acc: 0.5121 - val_loss: 0.6926 - val_acc: 0.5190\n",
      "Epoch 2/5\n",
      "947/947 [==============================] - 245s 259ms/step - loss: 0.6922 - acc: 0.5227 - val_loss: 0.6927 - val_acc: 0.5190\n",
      "Epoch 3/5\n",
      "947/947 [==============================] - 246s 260ms/step - loss: 0.6924 - acc: 0.5227 - val_loss: 0.6927 - val_acc: 0.5190\n",
      "Epoch 4/5\n",
      "947/947 [==============================] - 256s 270ms/step - loss: 0.6927 - acc: 0.5227 - val_loss: 0.6925 - val_acc: 0.5190\n",
      "Epoch 5/5\n",
      "947/947 [==============================] - 251s 265ms/step - loss: 0.6920 - acc: 0.5227 - val_loss: 0.6925 - val_acc: 0.5190\n",
      "Accuracy: 0.5386635843366612, Precision: 0.29043748487833254, Recall: 0.5386635843366612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunwoo/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "machine_learning_models(X,y,'lstm',True,type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_models(X,y,'lstm',True,type=\"counts\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_models(X,y,'lstm',False,type=\"counts\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_models(X,y,'lstm',False,type=\"binary\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_models(X,y,'lstm',False,type=\"tfidf\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
